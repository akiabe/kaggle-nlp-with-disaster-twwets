{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disaster_twwts_kaggle.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPq2HekTDTQqBYhaur6OHvF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akiabe/kaggle-nlp-with-disaster-twwets/blob/master/Disaster_twwts_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zupdbuQsI4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spPpIHnOBsKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size=7614\n",
        "test_portion=.1  # 10 % of teest set\n",
        "\n",
        "corpus = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMWzwv4zsOgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data from csv file to list\n",
        "num_sentences = 0\n",
        "\n",
        "import csv\n",
        "\n",
        "# Remove LATIN1 encoding from csv file\n",
        "with open(\"/tmp/train_cleaned.csv\") as csvfile:\n",
        "  reader = csv.reader(csvfile, delimiter=',')\n",
        "\n",
        "  for row in reader:\n",
        "    list_item = []\n",
        "\n",
        "    list_item.append(row[3])\n",
        "    list_item.append(row[4])\n",
        "\n",
        "    num_sentences = num_sentences + 1\n",
        "    corpus.append(list_item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY04as5yIQ1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "471d9aba-4571-4018-ce3b-efdafc897e3b"
      },
      "source": [
        "print(\"number of sentences :\", num_sentences)\n",
        "print(\"Length of corpus :\",len(corpus))\n",
        "print(\"Corpus :\", corpus[1:3])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of sentences : 7614\n",
            "Length of corpus : 7614\n",
            "Corpus : [['And so it begins.. day one of the snow apocalypse', '1'], ['@DanHRothschild Greed is the fuel of self-destruction. #Takecare', '0']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyscem9uDdNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random shuffle the corpus and split into sentences and labels\n",
        "import random\n",
        "\n",
        "sentences=[]\n",
        "labels=[]\n",
        "\n",
        "random.shuffle(corpus)\n",
        "\n",
        "for x in range(training_size):\n",
        "    sentences.append(corpus[x][0])\n",
        "    labels.append(corpus[x][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EAbQC9hJFiv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "816070e5-43e8-4b21-e099-918a4e2288c0"
      },
      "source": [
        "print(\"sentences numbers :\", len(sentences))\n",
        "print(\"labels numbers :\", len(labels))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentences numbers : 7614\n",
            "labels numbers : 7614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8w6DwBtJGp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Tokenizer will then be fit on the sentences\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Word index of tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "vocab_size = len(word_index)\n",
        "\n",
        "# Convert sentences into sequence of numbers\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "# Padding zero after the sentense\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "\n",
        "# Split sentenses and labels to training and test set\n",
        "split = int(test_portion * training_size)\n",
        "\n",
        "test_sequences = padded[0: split]\n",
        "training_sequences = padded[split: training_size]\n",
        "test_labels = labels[0: split]\n",
        "training_labels = labels[split: training_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3hTdjU6Jm-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "083b8e82-8100-4024-e491-e915603f014d"
      },
      "source": [
        "print(vocab_size)\n",
        "print(word_index['i'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22737\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI28daglJpnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert padded and labels data into np.array \n",
        "import numpy as np\n",
        "\n",
        "training_sequences = np.array(training_sequences)\n",
        "training_labels = np.array(training_labels)\n",
        "\n",
        "test_sequences = np.array(test_sequences)\n",
        "test_labels = np.array(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSlPlnzYJs_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}